## Title: Ultimate Private AI

### Level:

Intermediate

### Description:

Model servers are critical to any AI solution today, but many applications don't need the power—or cost—of cloud-based inference. A private model server tailored to your specific problem can work just as well, if not better, while being less expensive to run and deploy. Better still: build an application that interacts with models directly, with no server at all.

Projects like Yzma and Kronk make this a reality. Learn to write software that interacts with open source models directly. Build your own model server when you need one. Use the Kronk SDK for hardware-accelerated local inference with llama.cpp integrated directly into your Go applications via Yzma—no CGO required.

### What a student is expected to learn:

- Use llama.cpp libraries directly in Go applications via the Yzma project
- Build robust Go applications that interact with open source models from Hugging Face via Kronk
- Build a model server with an OpenAI-compatible chat completions API for tailored needs

### Prerequisites:

- It is expected that you will have been coding in Go for several months.
- A working Go environment running on the device you will be bringing to class.Hardware Requirements:
- Mac M1 series with at least 16 GB RAM (pref 32GB+).
- or any Linux/Windows laptop with a dedicated GPU with at least 8GB VRAM (not system ram) (pref 16GB).
- or access to a cloud-based instance with a dedicated GPU with at least 8GB VRAM (pref 16GB).

### Recommended Preparation:

- Please clone the main repo (https://github.com/ardanlabs/kronk) for the class.
- Please read the notes in the makefile for installing all the tooling and testing the code before class.
- Please email the instructor, Bill Kennedy, for assistance.
