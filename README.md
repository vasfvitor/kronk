# kronk

This project lets you use Go for hardware accelerated local inference with llama.cpp directly integrated into your applications. It provides a high level API based on the [yzma](https://github.com/hybridgroup/yzma) module.

Copyright 2025 Ardan Labs  
hello@ardanlabs.com

[![Linux](https://github.com/ardanlabs/llamacpp/actions/workflows/linux.yml/badge.svg)](https://github.com/ardanlabs/llamacpp/actions/workflows/linux.yml)
[![macOS](https://github.com/ardanlabs/llamacpp/actions/workflows/macos.yml/badge.svg)](https://github.com/ardanlabs/llamacpp/actions/workflows/macos.yml)

## My Information

```
Name:    Bill Kennedy
Company: Ardan Labs
Title:   Managing Partner
Email:   bill@ardanlabs.com
Twitter: goinggodotnet
```

### Examples

You can find examples in the ArdanLabs AI training repo at example13:

https://github.com/ardanlabs/ai-training/tree/main/cmd/examples/example13
